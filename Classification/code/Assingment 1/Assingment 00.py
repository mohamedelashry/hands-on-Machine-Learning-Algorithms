import math
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.datasets import load_svmlight_file
from sklearn.linear_model import LogisticRegression


def get_data(df):
    # load_svmlight_file loads dataset into sparse CSR matrix
    X,Y = load_svmlight_file(df)
    return X,Y

def split_data(n,train_size):
    tr_idx = np.random.choice(n, \
             int(np.round(n * train_size)),replace=False)
    te_idx = np.setdiff1d(np.arange(0,n), tr_idx)
    return tr_idx, te_idx


def standardize_para(X):
    Xmean = X.mean(axis=0)
    Xstd = X.std(axis=0)
    return {'X_mean' : Xmean, 'X_std': Xstd.T}


def standardize_X(X, stand_parms):
    return (X - stand_parms['X_mean']) / stand_parms['X_std']



##The sigmoid function adjusts the cost function hypotheses to adjust the algorithm proportionally for worse estimations
def Sigmoid(z):
	G_of_Z = float(1.0 / float((1.0 + math.exp(-1.0*z))))
	return G_of_Z 

##The hypothesis is the linear combination of all the known factors x[i] and their current estimated coefficients theta[i] 
##This hypothesis will be used to calculate each instance of the Cost Function
def Hypothesis(theta, x):
	z = 0
	for i in range(len(theta)):
		z += x[i]*theta[i]
	return Sigmoid(z)

##For each member of the dataset, the result (Y) determines which variation of the cost function is used
##The Y = 0 cost function punishes high probability estimations, and the Y = 1 it punishes low scores
##The "punishment" makes the change in the gradient of ThetaCurrent - Average(CostFunction(Dataset)) greater
def Cost_Function(X,Y,theta,m):
	sumOfErrors = 0
	for i in range(m):
		xi = X[i]
		hi = Hypothesis(theta,xi)
		if Y[i] == 1:
			error = Y[i] * math.log(hi)
		elif Y[i] == 0:
			error = (1-Y[i]) * math.log(1-hi)
		sumOfErrors += error
	const = -1/m
	J = const * sumOfErrors
	print ('cost is ', J ,"\n__________________________________")
	return J

##This function creates the gradient component for each Theta value 
##The gradient is the partial derivative by Theta of the current value of theta minus 
##a "learning speed factor aplha" times the average of all the cost functions for that theta
##For each Theta there is a cost function calculated for each member of the dataset
def Cost_Function_Derivative(X,Y,theta,j,m,alpha):
	sumErrors = 0
	for i in range(m):
		xi = X[i]
		xij = xi[j]
		hi = Hypothesis(theta,X[i])
		error = (hi - Y[i])*xij
		sumErrors += error
	m = len(Y)
	constant = float(alpha)/float(m)
	J = constant * sumErrors
	return J

##For each theta, the partial differential 
##The gradient, or vector from the current point in Theta-space (each theta value is its own dimension) to the more accurate point, 
##is the vector with each dimensional component being the partial differential for each theta value
def Gradient_Descent(X,Y,theta,m,alpha):
	new_theta = []
	constant = alpha/m
	for j in range(len(theta)):
		CFDerivative = Cost_Function_Derivative(X,Y,theta,j,m,alpha)
		new_theta_value = theta[j] - CFDerivative
		new_theta.append(new_theta_value)
	return new_theta

##The high level function for the LR algorithm which, for a number of steps (num_iters) finds gradients which take 
##the Theta values (coefficients of known factors) from an estimation closer (new_theta) to their "optimum estimation" which is the
##set of values best representing the system in a linear combination model
def trainLR (X,Y,alpha,theta,num_iters):
    m=len(Y)
    acclist=[]
    for x in range(num_iters):
        new_theta=Gradient_Descent(X, Y, theta, m, alpha)
        theta=new_theta
        if x % 100 == 0 :
            print("epoch # : " , x+100 ,'\ntheta ', theta ,"\n-------------")
            Cost_Function(X, Y, theta, m)
            acclist.append(accuracy(X,Y,theta))
    return theta ,acclist
    
##This method compares the accuracy of the model generated by the scikit library with the model generated by this implementation
def Declare_Winner(theta):
    score = 0
    winner = ""
    #first scikit LR is tested for each independent var in the dataset and its prediction is compared against the dependent var
    #if the prediction is the same as the dataset measured value it counts as a point for thie scikit version of LR
    scikit_score = clf.score(Xte,Yte)
    length = len(Xte)
    for i in range(length):
        prediction = round(Hypothesis(Xte[i],theta))
        answer = Yte[i]
        if prediction == answer:
            score += 1
    #the same process is repeated for the implementation from this module and the scores compared to find the higher match-rate
    my_score = float(score) / float(length)
    if my_score > scikit_score:
        print ('You won!')
    elif my_score == scikit_score:
        print ('Its a tie!')
    else:
        print( 'Scikit won.. :(')
    print ('Your accuracy score: ', my_score)
    print ('Scikits accuracy score: ', scikit_score )

def accuracy(x , y , w):
    yhat = testLR(w, x)
    accuracy = np.sum(y == yhat) / len(y)
    return accuracy

def testLR(ntheta, X):
    theta=np.matrix(ntheta)
    probability = 1/(1+np.exp(-(X * theta.T)))
    # print(probability.shape)
    probability = [1 if x >= 0.5 else 0 for x in probability]
    # print(probability)
    return probability


if __name__ == '__main__':

    X,Y = get_data("C:\\Users\\decim\\Desktop\\review with practice on machine learning algorithms\\Classification\\code\\Assingment\\diabetes")

    X = X.toarray()
    Y = np.where(Y == -1, 0, 1)
    
    # print(type(X))
    # print(Y)
    
    # print(X.shape)

    tr_idx, te_idx = split_data(X.shape[0],train_size = 0.8)
    
    Xtr = X[tr_idx,:]
    Ytr = Y[tr_idx];
    Xte = X[te_idx,:]
    Yte = Y[te_idx]

    #normalize the data
    stand_param = standardize_para(Xtr)
    Xtr = standardize_X(Xtr, stand_param)
    stand_param = standardize_para(Xte)
    Xte = standardize_X(Xte, stand_param)
    
    # print(Xtr)
    
    feature_name = ['Pregnancies', 'Glucose', 'BloodPressure', \
                'SkinThickness','Insulin', 'BMI',\
                'DiabetesPedigreeFunction', 'Age']
    ntr = Xtr.shape[0]
    feat1_neg = [Xtr[ii,1] for ii in range(0, ntr) if Ytr[ii]==0]
    feat2_neg = [Xtr[ii,5] for ii in range(0, ntr) if Ytr[ii]==0]
    feat1_pos = [Xtr[ii,1] for ii in range(0, ntr) if Ytr[ii]==1]
    feat2_pos = [Xtr[ii,5] for ii in range(0, ntr) if Ytr[ii]==1]

    plt.scatter(feat1_neg, feat2_neg, color = "r", label="label 0")
    plt.scatter(feat1_pos, feat2_pos, color = "b", label="label 1")
    plt.legend()
    plt.xlabel(feature_name[1])
    plt.ylabel(feature_name[5])
    plt.show()

    Xtr = np.hstack((Xtr,np.ones((Xtr.shape[0],1))))
    Xtr = np.insert(Xtr, 0, 1, axis=1)
    Xte = np.hstack((Xte,np.ones((Xte.shape[0],1))))
    Xte = np.insert(Xte, 0, 1, axis=1)
    
  
    
    # train scikit learn model 
    clf = LogisticRegression()
    clf.fit(Xtr,Ytr)
    print ('score Scikit learn: ', clf.score(Xte,Yte))
                     
    # These are the initial guesses for theta as well as the learning rate of the algorithm
    # A learning rate too low will not close in on the most accurate values within a reasonable number of iterations
    # An alpha too high might overshoot the accurate values or cause irratic guesses
    # Each iteration increases model accuracy but with diminishing returns, 
    # and takes a signficicant coefficient times O(n)*|Theta|, n = dataset length
    initial_theta = np.array(np.zeros(Xtr.shape[1]))
    alpha = 0.001
    iterations = 1000
    TR_theta , acclist = trainLR(Xtr,Ytr,alpha,initial_theta,iterations)
    
    ## Declare  Winner
    print("Classification accuracy:", accuracy(Xte, Yte ,TR_theta))
    Declare_Winner(TR_theta)
    
    # the accuracy as a function of epochs Plot
    epoc = [100,200,300,400,500,600,700,800,900,1000]
    plt.scatter( epoc,acclist, color = "r")
    plt.xlabel("# epoch")
    plt.ylabel("accurecy")
    plt.show()